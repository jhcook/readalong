# US2.2: Real‑Time STT Transcription

## State
COMMITTED

## Problem Statement
We need to convert spoken audio into text and timestamps in near real-time to drive the highlighting engine. This must happen on-device to support the offline/privacy goals.

## User Story
As a system I want to transcribe speech in real time So that I can align spoken words to text.

## Acceptance Criteria
- [x] **AC1**: Whisper.cpp or Vosk runs locally.
- [x] **AC2**: Transcription latency is under 300ms.
- [x] **AC3**: Timestamps are generated for each word or phrase.
- [x] **AC4**: Transcription accuracy is logged for debugging.

## Non-Functional Requirements
- Performance (Latency < 300ms)
- Resource Usage (CPU/Memory limits)
### Security
- [x] No PII in logs
- [x] No secrets in code
- [x] Compliance docs checked if applicable
### Compliance
- [x] No PII in logs
- [x] No secrets in code
- [x] Compliance docs checked if applicable
### Observability
- [x] Is OpenTelemetry added for new flows?
- [x] Are logs structured and governed?

## Linked ADRs
- ADR-002: Use Whisper.cpp for Local Speech‑to‑Text
- ADR-003: Use Forced Alignment for Word‑Level Highlighting

## Impact Analysis Summary
Components touched: STT Engine Wrapper, WASM/Native Modules
Workflows affected: Reading/Playback
Risks identified: High CPU usage on older devices; Model download size.
**Architect Governance**:
- [x] Do ADRs exist for major changes?
- [x] Are architectural boundaries respected?
**Product Governance**:
- [x] Are Acceptance Criteria clear and testable?
- [x] Is the Impact Analysis complete?

## Test Strategy
How will we verify correctness?
- Benchmark latency on target devices.
- Accuracy tests against standard audio datasets (WER calculation).
- Stress tests for long sessions.

**QA Governance**:
- [x] Are there new tests for new features?
- [x] Is the Test Strategy section in the Story comprehensive?

## Rollback Plan
How do we revert safely?
- Revert STT integration changes.
- Switch back to previous model version if applicable.
