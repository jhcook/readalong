# US2.2: Real‑Time STT Transcription

## State
DRAFT

## Problem Statement
We need to convert spoken audio into text and timestamps in near real-time to drive the highlighting engine. This must happen on-device to support the offline/privacy goals.

## User Story
As a system I want to transcribe speech in real time So that I can align spoken words to text.

## Acceptance Criteria
- [ ] **AC1**: Whisper.cpp or Vosk runs locally.
- [ ] **AC2**: Transcription latency is under 300ms.
- [ ] **AC3**: Timestamps are generated for each word or phrase.
- [ ] **AC4**: Transcription accuracy is logged for debugging.

## Non-Functional Requirements
- Performance (Latency < 300ms)
- Resource Usage (CPU/Memory limits)
### Security
- [ ] No PII in logs
- [ ] No secrets in code
- [ ] Compliance docs checked if applicable
### Compliance
- [ ] No PII in logs
- [ ] No secrets in code
- [ ] Compliance docs checked if applicable
### Observability
- [ ] Is OpenTelemetry added for new flows?
- [ ] Are logs structured and governed?

## Linked ADRs
- ADR-002: Use Whisper.cpp for Local Speech‑to‑Text
- ADR-003: Use Forced Alignment for Word‑Level Highlighting

## Impact Analysis Summary
Components touched: STT Engine Wrapper, WASM/Native Modules
Workflows affected: Reading/Playback
Risks identified: High CPU usage on older devices; Model download size.
**Architect Governance**:
- [ ] Do ADRs exist for major changes?
- [ ] Are architectural boundaries respected?
**Product Governance**:
- [ ] Are Acceptance Criteria clear and testable?
- [ ] Is the Impact Analysis complete?

## Test Strategy
How will we verify correctness?
- Benchmark latency on target devices.
- Accuracy tests against standard audio datasets (WER calculation).
- Stress tests for long sessions.

**QA Governance**:
- [ ] Are there new tests for new features?
- [ ] Is the Test Strategy section in the Story comprehensive?

## Rollback Plan
How do we revert safely?
- Revert STT integration changes.
- Switch back to previous model version if applicable.
